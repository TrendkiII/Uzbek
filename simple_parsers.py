import requests
from bs4 import BeautifulSoup
from urllib.parse import quote
import time
from config import ITEMS_PER_PAGE
from utils import generate_item_id, make_full_url, get_next_user_agent, logger  # –î–û–ë–ê–í–ò–õ logger

def parse_mercari(keyword):
    """–°–∏–Ω—Ö—Ä–æ–Ω–Ω—ã–π –ø–∞—Ä—Å–µ—Ä Mercari"""
    items = []
    url = f"https://jp.mercari.com/search?keyword={quote(keyword)}"
    headers = {'User-Agent': get_next_user_agent()}
    
    try:
        logger.info(f"–ü–∞—Ä—Å–∏–Ω–≥ Mercari: {keyword}")
        r = requests.get(url, headers=headers, timeout=10)
        if r.status_code != 200:
            logger.warning(f"Mercari –≤–µ—Ä–Ω—É–ª {r.status_code}")
            return items
            
        soup = BeautifulSoup(r.text, 'lxml')
        cards = soup.select('[data-testid="item-cell"]')[:ITEMS_PER_PAGE]
        
        for card in cards:
            try:
                title_elem = card.select_one('[data-testid="thumbnail-title"]')
                price_elem = card.select_one('[data-testid="price"]')
                link_elem = card.select_one('a')
                
                if not title_elem or not link_elem:
                    continue
                
                title = title_elem.text.strip()
                price = price_elem.text.strip() if price_elem else '0'
                href = link_elem.get('href')
                full_url = make_full_url('https://jp.mercari.com', href)
                
                items.append({
                    'id': generate_item_id({'source': 'Mercari JP', 'url': full_url, 'title': title}),
                    'title': title[:100],
                    'price': price[:50],
                    'url': full_url,
                    'source': 'Mercari JP',
                    'img_url': '',  # –î–æ–±–∞–≤–∏–ª –ø—É—Å—Ç–æ–µ –ø–æ–ª–µ
                })
            except Exception as e:
                logger.debug(f"–û—à–∏–±–∫–∞ –ø–∞—Ä—Å–∏–Ω–≥–∞ –∫–∞—Ä—Ç–æ—á–∫–∏: {e}")
                
    except Exception as e:
        logger.error(f"–û—à–∏–±–∫–∞ –∑–∞–ø—Ä–æ—Å–∞ Mercari: {e}")
    
    logger.info(f"–ù–∞–π–¥–µ–Ω–æ {len(items)} —Ç–æ–≤–∞—Ä–æ–≤ –Ω–∞ Mercari")
    return items

def search_all(keywords):
    """–ó–∞–ø—É—Å–∫–∞–µ—Ç –ø–æ–∏—Å–∫ –ø–æ –≤—Å–µ–º –∫–ª—é—á–∞–º"""
    all_items = []
    for keyword in keywords:
        logger.info(f"–ò—â–µ–º '{keyword}'...")
        items = parse_mercari(keyword)
        all_items.extend(items)
        time.sleep(2)  # –∑–∞–¥–µ—Ä–∂–∫–∞ –º–µ–∂–¥—É –∑–∞–ø—Ä–æ—Å–∞–º–∏
    return all_items

# ============== –î–û–ë–ê–í–õ–Ø–ï–ú –§–£–ù–ö–¶–ò–Æ –î–õ–Ø –°–û–í–ú–ï–°–¢–ò–ú–û–°–¢–ò ==============
async def run_parser(platform, query, price_min=0, price_max=1000000, max_items=50):
    """
    –ê—Å–∏–Ω—Ö—Ä–æ–Ω–Ω–∞—è —Ñ—É–Ω–∫—Ü–∏—è –¥–ª—è –∑–∞–ø—É—Å–∫–∞ –ø–∞—Ä—Å–µ—Ä–∞ (—Å–æ–≤–º–µ—Å—Ç–∏–º–æ—Å—Ç—å —Å simple_bot.py)
    """
    import asyncio
    
    logger.info(f"üîç –ó–∞–ø—É—Å–∫ –ø–∞—Ä—Å–µ—Ä–∞ –¥–ª—è {platform}, –∑–∞–ø—Ä–æ—Å: {query}")
    
    # –ü–æ–∫–∞ –ø–æ–¥–¥–µ—Ä–∂–∏–≤–∞–µ–º —Ç–æ–ª—å–∫–æ Mercari
    if platform in ["mercari", "Mercari JP", "mercari jp"]:
        # –ó–∞–ø—É—Å–∫–∞–µ–º —Å–∏–Ω—Ö—Ä–æ–Ω–Ω—ã–π –ø–∞—Ä—Å–µ—Ä –≤ –æ—Ç–¥–µ–ª—å–Ω–æ–º –ø–æ—Ç–æ–∫–µ
        loop = asyncio.get_event_loop()
        items = await loop.run_in_executor(None, parse_mercari, query)
        return items[:max_items]
    else:
        # –î–ª—è –¥—Ä—É–≥–∏—Ö –ø–ª–∞—Ç—Ñ–æ—Ä–º –≤–æ–∑–≤—Ä–∞—â–∞–µ–º –ø—É—Å—Ç–æ–π —Å–ø–∏—Å–æ–∫
        logger.warning(f"‚ö†Ô∏è –ü–ª–∞—Ç—Ñ–æ—Ä–º–∞ {platform} –ø–æ–∫–∞ –Ω–µ –ø–æ–¥–¥–µ—Ä–∂–∏–≤–∞–µ—Ç—Å—è")
        return []